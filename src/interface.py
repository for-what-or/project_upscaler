import json
import numpy as np
import streamlit as st
import time
from io import BytesIO
from PIL import Image
from src.model import *
from src.model_folder import *
from src.ui.dialogs import *
from streamlit_image_comparison import image_comparison

config = json.load(open('src/config.json'))
model_list = json.load(open('src/model_list.json'))

models_path = config["models_path"]
model_edit_permission = config["model_edit_permission"]

@st.cache_resource
def get_model(model_type):
    return load_sr_model(models_path + '/' + model_type + '.pth')

def main():
    model_list = json.load(open('src/model_list.json'))
    st.set_page_config(
        page_title="–ê–ø—Å–∫–µ–π–ª–µ—Ä",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("üñºÔ∏è –ê–ø—Å–∫–µ–π–ª–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    st.markdown("""
    –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π.  
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —á–∞—Å—Ç—è–º.
    """)

    with st.sidebar:
        if st.button("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è"):
            instruction_dialog()

        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        model_device = st.radio(
            "–£—Å—Ç—Ä–æ–∏ÃÜ—Å—Ç–≤–æ",
            ["cuda"],
            index=0,
            help="–í—ã–±–µ—Ä–∏—Ç–µ —É—Å—Ç—Ä–æ–∏ÃÜ—Å—Ç–≤–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è cuda)"
        )
        
        model_type = st.radio(
            "–ú–æ–¥–µ–ª–∏",
            load_model_list(models_path),
            index=0,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"
        )
        
        if st.button("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏"):
            # –û–∫–Ω–æ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏
            if model_edit_permission:
                manage_models_dialog()
            else:
                st.error("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω")

        selected_model = next((model for model in model_list if model["model_name"] == model_type), None)
        scale_factor = selected_model["scale_factor"] if selected_model else 1
        st.info(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ **{model_type}: {selected_model['scale_factor']}**")
        
        tile_size = st.slider(
            "–†–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞",
            32, 512, 128,
            help="–ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏, –±–æ–ª—å—à–∏–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"
        )
        
        show_metrics = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞", False)

    col1, col2 = st.columns(2)
    proc_time = 0
    with col1:
        global image
        image = None
        uploaded_file = st.file_uploader(
            "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            type=["jpg", "png", "jpeg"],
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–∞–π–ª—ã JPG, JPEG –∏ PNG."
        )
        
        if uploaded_file:
            image = Image.open(uploaded_file)
            '''st.image(
                image,
                caption="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                use_container_width=True
            )'''

    with col2:
        global result_img
        result_img = None
        if uploaded_file:
            if st.button("üöÄ –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ", type="primary"):
                start_time = time.time()
                device = torch.device(model_device if torch.cuda.is_available() else "cpu")

                with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
                    model = get_model(model_type)
                
                model.to(device)
                
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
                    tiles, positions = split_image(image, tile_size)
                    processed_tiles = []
                    
                    
                    progress_text = "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–ª–æ–≤."
                    my_bar = st.progress(0, text=progress_text)

                    for i, tile in enumerate(tiles):
                        with torch.no_grad():
                            processed_tile = model(tile)
                        processed_tiles.append(processed_tile)
                        progress_text = f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–∞–π–ª–æ–≤. ({i+1}/{len(tiles)})"
                        my_bar.progress(int((i+1)/len(tiles)*100), text=progress_text)
                    
                    result = merge_tiles(processed_tiles, positions, image.size, scale_factor)
                    
                    result_img = result.permute(1, 2, 0).clamp(0, 1).cpu().numpy()
                    result_img = Image.fromarray((result_img * 255).astype(np.uint8))
                
                proc_time = time.time() - start_time
                
                '''st.image(
                    result_img,
                    caption=f"–£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                    use_container_width=True
                )'''
                
                # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                buf = BytesIO()
                result_img.save(buf, format="PNG")
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                    buf.getvalue(),
                    f"upscaled_picture.png",
                    "image/png"
                )
                
    if image and result_img:
        image_comparison(
            img1=image,
            img2=result_img,
            width=1280,
            label1="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            label2="–†–µ–∑—É–ª—å—Ç–∞—Ç",
        )
    
    if show_metrics:
        st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏")
        st.metric("–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", f"{proc_time:.2f} —Å–µ–∫")
        st.metric("–†–∞–∑–º–µ—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª–∞", f"{image.size[0]}x{image.size[1]}")
        st.metric("–†–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", f"{result_img.size[0]}x{result_img.size[1]}")